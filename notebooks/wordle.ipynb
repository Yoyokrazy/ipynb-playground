{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wordle\n",
    "\n",
    "Basic EDA for a daily sample of Wordle results [tweets](https://www.kaggle.com/datasets/benhamner/wordle-tweets). Make sure to download the tweets data, and save the unzipped csv file into this repo's data folder (i.e. `./data/tweets.csv`) before running this notebook. Any new Wordle words need to be mapped for analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(url=\"image/wordle.png\", width=300)\n",
    "# can also insert as markdown: ![wordle](image/wordle.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install matplotlib\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets = pd.read_csv('data/tweets.csv')\n",
    "df_tweets.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets['tweet_date'] = pd.to_datetime(df_tweets['tweet_date'])\n",
    "df_tweets['tweet_date_only'] = df_tweets['tweet_date'].dt.date\n",
    "df_tweets['n_attempts'] = df_tweets['tweet_text'].str[11].astype('int')\n",
    "\n",
    "# make each tweet consistent\n",
    "df_tweets['tweet_text'] = df_tweets['tweet_text'].str.replace('â¬œ','â¬›')\n",
    "# parse each guess\n",
    "for n in range(6):\n",
    "    n += 1\n",
    "    # figure out if it even has a guess\n",
    "    df_tweets[f'has_guess{n}'] = \\\n",
    "        df_tweets['tweet_text'].str.split('\\n') \\\n",
    "            .str[n + 1].str.contains('|'.join(['ðŸŸ¨','â¬›','ðŸŸ©'])) \\\n",
    "            .fillna(False)\n",
    "\n",
    "    # Add the text if it's a guess\n",
    "    df_tweets.loc[df_tweets[f'has_guess{n}'], f'guess{n}'] = \\\n",
    "        df_tweets['tweet_text'].str.split('\\n').str[n + 1].str[:5]\n",
    "\n",
    "    df_tweets.loc[df_tweets[f'has_guess{n}'],\n",
    "               f'guess{n}_incorrect'] = df_tweets[f'guess{n}'].str.count('â¬›')\n",
    "    df_tweets.loc[df_tweets[f'has_guess{n}'],\n",
    "               f'guess{n}_wrong_spot'] = df_tweets[f'guess{n}'].str.count('ðŸŸ¨')\n",
    "    df_tweets.loc[df_tweets[f'has_guess{n}'],\n",
    "               f'guess{n}_correct'] = df_tweets[f'guess{n}'].str.count('ðŸŸ©')\n",
    "    df_tweets.loc[df_tweets[f'guess{n}_correct'] == 6, 'final_guess'] = n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick look at data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets.groupby(\"wordle_id\")[\"wordle_id\"].count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets['tweet_date_only'].value_counts().plot(figsize=(12, 5), title='Wordle Tweets by Day', color='orange')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets['day'] = df_tweets['tweet_date'].dt.day_name()\n",
    "df_tweets.groupby(['tweet_date_only','day'])['n_attempts'].value_counts().unstack().style.background_gradient(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets.groupby('day')['n_attempts'].value_counts().unstack().style.background_gradient(axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map to actual words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dict = {\n",
    "        '210' : 'PANIC',\n",
    "        '211' : 'SOLAR',\n",
    "        '212' : 'SHIRE',\n",
    "        '213' : 'PROXY',\n",
    "        '214' : 'POINT',\n",
    "        '215' : 'ROBOT',\n",
    "        '216' : 'PRICK'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dict = {int(k):str(v) for k,v in map_dict.items()}\n",
    "\n",
    "df_tweets['answer'] = df_tweets['wordle_id'].map(map_dict)\n",
    "df_tweets.groupby('answer')['n_attempts'].value_counts().unstack().style.background_gradient(axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### sub section  mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets.groupby('answer')['n_attempts'].value_counts().unstack().style.background_gradient(axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets['n_attempts'].value_counts().sort_index().plot(kind='barh', title='Number of Attempts', color='purple')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the correctly guessed first letters\n",
    "first_guess_correct = []\n",
    "for i, d in df_tweets.dropna(subset=['answer']).iterrows():\n",
    "    example_text = d['guess1']\n",
    "    example_solution = d['answer']\n",
    "    results =[x.span()[0] for x in re.finditer('ðŸŸ©', example_text)]\n",
    "    first_guess_letters = [example_solution[i] for i in results]\n",
    "    first_guess_correct += first_guess_letters\n",
    "\n",
    "pd.Series(first_guess_correct).value_counts(ascending=True) \\\n",
    "    .plot(kind='barh', figsize=(10, 5), color='green',\n",
    "          title='Most Common Correct Guessed Letters on First Try')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_pal = ['#2ca02c', '#fcd53f', '#000000']\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(12, 5), sharex=True)\n",
    "\n",
    "for i, x in enumerate(['_correct','_wrong_spot','_incorrect']):\n",
    "    col_subset = [c for c in df_tweets.columns if x in c]\n",
    "    guess_avg = df_tweets[col_subset].mean()\n",
    "    guess_avg.index = [f'Guess {i+1}' for i in range(6)]\n",
    "    guess_avg.sort_index(ascending=False).plot(kind='barh',\n",
    "              title=f'{x.strip(\"_\").replace(\"_\",\" \").title()}',\n",
    "              ax=axs[i], color=color_pal[i])\n",
    "    axs[i].set_xlabel('Average Number of Letters')\n",
    "fig.suptitle('Wordle Average Results by Guess Number', fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess1_split = df_tweets.set_index('tweet_id') \\\n",
    "    ['guess1'].str.split('', expand=True) \\\n",
    "    .drop([0, 6], axis=1)\n",
    "\n",
    "guess1_split = guess1_split.unstack().reset_index() \\\n",
    "    .rename(columns={'level_0':'letter_loc',\n",
    "                     0:'result'})\n",
    "\n",
    "guess1_split.groupby('letter_loc')['result'] \\\n",
    "    .value_counts().unstack().T \\\n",
    "    .style.background_gradient()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = [*map_dict.values()]\n",
    "unique_word_list = np.unique(word_list)\n",
    "\n",
    "first_letter_list = [word[0] for word in list(unique_word_list)]\n",
    "count = Counter(first_letter_list)\n",
    "\n",
    "plt.rc(\"figure\", autolayout=True, figsize=(13, 5))\n",
    "ax = plt.bar(*zip(*count.most_common()), color='green')\n",
    "plt.title(\"First Letter Frequencies for Valid Answers\");\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "862d14ab81ccfcaf0c988adcd9ecbb2c10a6849425b12f95546c43a1f81ae403"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
